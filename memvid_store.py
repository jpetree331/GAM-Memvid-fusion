"""
Memvid Store - The Librarian Architecture

============================================================
THE VAULT: Store Full, Raw Conversation Threads
============================================================

This implementation follows "The Librarian" pattern:

1. STORAGE: Store complete, raw conversation exchanges ("Pearls")
   - No summarization of body text
   - User inputs may be 3-page essays - preserve EVERYTHING
   - Metadata tags generated by MemoryCondenser for indexing

2. RETRIEVAL: Raw frames are passed to the Synthesizer Node
   - Search finds relevant Pearls
   - Synthesizer (gpt-4o-mini) creates detailed abstracts
   - Abstracts (200-300 words) go into prompt context

3. SOFT DELETE: Append-only with status:deleted metadata pattern
   - Corrections don't corrupt history
   - Deleted frames excluded from search results

Each AI model (persona) gets its own isolated .mv2 vault file.
"""
import os
import json
from pathlib import Path
from datetime import datetime, timezone
from typing import Optional, List, Dict, Any, Tuple
from dataclasses import dataclass, field
from enum import Enum

from memory_entry import (
    MemoryEntry,
    MemoryCategory,
    ImportanceLevel,
    AISelfType,
    create_memory,
    create_ai_self_memory
)

# Memvid SDK imports (v2)
try:
    from memvid_sdk import create as memvid_create, use as memvid_use
    MEMVID_AVAILABLE = True
except ImportError:
    MEMVID_AVAILABLE = False
    print("[MemvidStore] WARNING: memvid-sdk not installed. Run: pip install memvid-sdk[fastembed]")

# Import config for embedding settings
from config import config

# Default embedding model for local embeddings (fastembed)
DEFAULT_EMBEDDING_MODEL = getattr(config, 'MEMVID_EMBEDDING_MODEL', 'BAAI/bge-small-en-v1.5')

# Debug flag for tracing SDK data types
_DEBUG_SDK_TYPES = True  # Set to False after debugging

# =============================================================================
# SUPER-INDEX ARCHITECTURE CONSTANTS
# =============================================================================
# The Super-Index strategy separates:
#   - INDEX (vector_text): Compact "Fingerprint" for embedding/search
#   - VAULT (metadata): Full, untruncated conversation payload
#
# This ensures we never lose data to truncation while maintaining
# efficient semantic search via the fingerprint.

# If combined text is shorter than this, use it directly as fingerprint
SHORT_TEXT_CHAR_THRESHOLD = 1000

# Maximum characters for the fingerprint (must fit embedding model context)
# bge-small supports ~512 tokens ≈ ~2000 chars, but we use 1500 for safety margin
# This ensures we never exceed the embedding model's context window
MAX_FINGERPRINT_CHARS = 1500

# OpenAI client for fingerprint generation (initialized lazily)
_openai_client = None


# =============================================================================
# SUPER-INDEX HELPER FUNCTIONS
# =============================================================================

def _get_openai_client():
    """
    Get or create the OpenAI client for fingerprint generation.

    Uses lazy initialization to avoid overhead if fingerprints aren't needed.
    Configured via environment variables or config module.
    """
    global _openai_client
    if _openai_client is None:
        import httpx
        _openai_client = httpx.Client(
            base_url=config.OPENAI_BASE_URL,
            headers={"Authorization": f"Bearer {config.OPENAI_API_KEY}"},
            timeout=60.0
        )
    return _openai_client


def build_fingerprint(user_message: str, ai_response: str) -> str:
    """
    Build a compact "Fingerprint" for the vector index.

    The fingerprint is what gets embedded for semantic search. It must be
    compact enough to fit the embedding model's context window (~512 tokens).

    Strategy:
    - Short conversations (≤1000 chars): Use the full text directly
    - Long conversations: Generate a summary + keyword list via LLM

    Args:
        user_message: The user's message
        ai_response: The AI's response

    Returns:
        A compact fingerprint string suitable for embedding

    Invariants:
        - Output is always ≤ MAX_FINGERPRINT_CHARS
        - Output is stripped of leading/trailing whitespace
    """
    combined = f"User: {user_message}\nAI: {ai_response}"

    # Short text: use directly
    if len(combined) <= SHORT_TEXT_CHAR_THRESHOLD:
        fingerprint = combined[:MAX_FINGERPRINT_CHARS]
        if _DEBUG_SDK_TYPES:
            print(f"[Fingerprint] Short text ({len(combined)} chars), using directly")
        return fingerprint.strip()

    # Long text: generate summary + keywords via LLM
    if _DEBUG_SDK_TYPES:
        print(f"[Fingerprint] Long text ({len(combined)} chars), generating summary...")

    try:
        client = _get_openai_client()

        # Truncate input to avoid token limits on the LLM call
        truncated_input = combined[:8000]  # ~2000 tokens input limit

        prompt = f"""You are creating a search index entry for a conversation between a user and an AI assistant.

Write a concise semantic summary of the core ideas in about 150 words.
Then append a line starting with 'Keywords:' followed by a comma-separated list of ALL specific entities, proper nouns, and distinct concepts mentioned (even minor ones, e.g., 'Blueberries', 'Spock', 'Romans 8').

Output format:
Summary: <one paragraph summary>
Keywords: <comma-separated keyword list>

CONVERSATION:
{truncated_input}"""

        response = client.post(
            "/chat/completions",
            json={
                "model": getattr(config, 'OPENAI_CONDENSER_MODEL', 'gpt-4o-mini'),
                "messages": [{"role": "user", "content": prompt}],
                "temperature": 0.3,
                "max_tokens": 500
            }
        )
        response.raise_for_status()

        result = response.json()
        fingerprint = result["choices"][0]["message"]["content"].strip()

        if _DEBUG_SDK_TYPES:
            print(f"[Fingerprint] Generated {len(fingerprint)} char summary")

    except Exception as e:
        print(f"[Fingerprint] LLM call failed: {e}, using truncated text")
        # Fallback: use truncated combined text
        fingerprint = combined

    # Hard truncate to ensure we never exceed embedding model limits
    fingerprint = fingerprint[:MAX_FINGERPRINT_CHARS].strip()

    return fingerprint


def payload_to_text(full_payload: dict) -> str:
    """
    Reconstruct the full conversation text from a stored payload.

    This is the inverse of storing: it takes the full_payload from metadata
    and returns the complete, untruncated conversation string.

    Args:
        full_payload: Dict with 'user' and 'ai' keys containing full messages

    Returns:
        Full conversation text: "User: {message}\nAI: {response}"
    """
    if not full_payload:
        return ""

    user = full_payload.get("user", "")
    ai = full_payload.get("ai", "")

    return f"User: {user}\nAI: {ai}"


def _safe_parse_metadata(meta: Any, debug_context: str = "") -> dict:
    """
    Safely parse metadata from Memvid SDK.

    The SDK may return metadata as a JSON string or as a dict.
    This helper ensures we always get a dict.

    Args:
        meta: The metadata value (could be str, dict, or None)
        debug_context: Context string for debug logging

    Returns:
        Parsed metadata dict
    """
    if meta is None:
        return {}

    if isinstance(meta, dict):
        return meta

    if isinstance(meta, str):
        # Metadata came back as JSON string - parse it
        if _DEBUG_SDK_TYPES:
            print(f"[Librarian DEBUG] Metadata is string in {debug_context}, parsing JSON...")
        try:
            parsed = json.loads(meta)
            if isinstance(parsed, dict):
                return parsed
            else:
                print(f"[Librarian] Warning: Parsed metadata is {type(parsed)}, expected dict")
                return {}
        except json.JSONDecodeError as e:
            print(f"[Librarian] Warning: Failed to parse metadata JSON: {e}")
            return {}

    # Unknown type
    if _DEBUG_SDK_TYPES:
        print(f"[Librarian DEBUG] Unexpected metadata type in {debug_context}: {type(meta)}")
    return {}


def _safe_parse_hit(hit: Any, debug_context: str = "") -> dict:
    """
    Safely parse a search hit from Memvid SDK.

    Args:
        hit: A search hit (could be dict or other)
        debug_context: Context for debug logging

    Returns:
        Hit as a dict
    """
    if hit is None:
        return {}

    if isinstance(hit, dict):
        return hit

    if isinstance(hit, str):
        if _DEBUG_SDK_TYPES:
            print(f"[Librarian DEBUG] Hit is string in {debug_context}, parsing JSON...")
        try:
            return json.loads(hit)
        except json.JSONDecodeError:
            return {"text": hit}

    # If it has a to_dict method, use it
    if hasattr(hit, 'to_dict'):
        return hit.to_dict()

    # If it has __dict__, use that
    if hasattr(hit, '__dict__'):
        return vars(hit)

    if _DEBUG_SDK_TYPES:
        print(f"[Librarian DEBUG] Unexpected hit type in {debug_context}: {type(hit)}")
        print(f"[Librarian DEBUG] Hit value: {str(hit)[:200]}")

    return {}


def _extract_hits_from_result(result: Any, debug_context: str = "") -> List[dict]:
    """
    Extract the hits array from a Memvid SDK find() result.

    The SDK returns: {'query': '...', 'hits': [...], 'took_ms': ..., ...}
    This helper extracts just the hits list.

    Args:
        result: The result from mv.find()
        debug_context: Context for debug logging

    Returns:
        List of hit dicts
    """
    if result is None:
        return []

    # If result is already a list, return it
    if isinstance(result, list):
        return result

    # If result is a dict with 'hits' key, extract it
    if isinstance(result, dict):
        hits = result.get("hits", [])
        if _DEBUG_SDK_TYPES and hits:
            print(f"[Librarian DEBUG] Extracted {len(hits)} hits from find() result in {debug_context}")
        return hits if isinstance(hits, list) else []

    # If it's a string, try parsing as JSON
    if isinstance(result, str):
        try:
            parsed = json.loads(result)
            return _extract_hits_from_result(parsed, debug_context)
        except json.JSONDecodeError:
            pass

    if _DEBUG_SDK_TYPES:
        print(f"[Librarian DEBUG] Unexpected find() result type in {debug_context}: {type(result)}")

    return []


class FrameStatus(str, Enum):
    """Status of a memory frame (Pearl)."""
    ACTIVE = "active"      # Normal, retrievable frame
    DELETED = "deleted"    # Soft-deleted, excluded from search
    ARCHIVED = "archived"  # Superseded by newer version
    DRAFT = "draft"        # Not yet finalized


@dataclass
class Pearl:
    """
    A Pearl is a complete conversation exchange (frame) in the vault.

    Pearls store the FULL, RAW conversation - no summarization.
    Metadata tags are used for indexing and retrieval.
    """
    id: str
    user_message: str           # Full user input (may be 3+ pages)
    ai_response: str            # Full AI response
    tags: List[str] = field(default_factory=list)  # #Theology, #Core, etc.
    category: str = "context"
    importance: str = "normal"
    emotional_tone: Optional[str] = None
    created_at: str = field(default_factory=lambda: datetime.now().isoformat())
    status: str = FrameStatus.ACTIVE.value
    user_name: str = "User"
    model_id: Optional[str] = None

    # Additional metadata
    thread_id: Optional[str] = None      # Conversation thread this belongs to
    message_index: Optional[int] = None  # Position in thread
    word_count: int = 0

    def __post_init__(self):
        """Calculate word count on creation."""
        self.word_count = len(self.user_message.split()) + len(self.ai_response.split())

    @property
    def full_content(self) -> str:
        """
        Get the complete raw content for display/synthesis.

        Note: With Super-Index architecture, this is NOT used for storage.
        Storage uses full_payload in metadata (never truncated).
        This property is for display and passing to the Synthesizer.
        """
        return f"User: {self.user_message}\nAI: {self.ai_response}"

    def get_label(self) -> str:
        """
        Generate the Memvid label for fast filtering.

        Format: "category:{cat}|importance:{imp}|status:{status}"
        """
        tag_str = "|".join(f"tag:{t}" for t in self.tags[:5])  # Limit tags in label
        return f"category:{self.category}|importance:{self.importance}|status:{self.status}|{tag_str}"

    def get_metadata(self) -> dict:
        """
        Get full metadata dict for Memvid storage.

        SUPER-INDEX ARCHITECTURE:
        - full_payload: Contains complete, untruncated user + AI messages
        - Other fields: Indexing metadata for filtering and organization

        The full_payload is the source of truth for retrieval.
        The vector_text (fingerprint) is only used for search, not storage.
        """
        return {
            # === VAULT: Full payload for retrieval (NEVER truncated) ===
            "full_payload": {
                "user": self.user_message,
                "ai": self.ai_response,
            },
            # === INDEXING METADATA ===
            "tags": self.tags,
            "category": self.category,
            "importance": self.importance,
            "emotional_tone": self.emotional_tone,
            "created_at": self.created_at,
            "status": self.status,
            "user_name": self.user_name,
            "thread_id": self.thread_id,
            "message_index": self.message_index,
            "word_count": self.word_count,
            "model_id": self.model_id
        }

    def to_dict(self) -> dict:
        """Convert to dictionary for serialization."""
        return {
            "pearl_id": self.id,
            "user_message": self.user_message,
            "ai_response": self.ai_response,
            "tags": self.tags,
            "category": self.category,
            "importance": self.importance,
            "emotional_tone": self.emotional_tone,
            "created_at": self.created_at,
            "status": self.status,
            "user_name": self.user_name,
            "thread_id": self.thread_id,
            "message_index": self.message_index,
            "word_count": self.word_count,
            "full_content": self.full_content
        }

    @classmethod
    def from_memvid_hit(cls, hit: Any, model_id: str) -> "Pearl":
        """
        Create a Pearl from a Memvid search hit.

        SUPER-INDEX ARCHITECTURE:
        - The hit.text contains the fingerprint (for search), NOT full content
        - The hit.metadata contains full_payload with complete conversation
        - We ALWAYS read from full_payload, never parse hit.text for content

        This ensures we never lose data to truncation.
        """
        # Safely parse the hit (may be dict or other type from SDK)
        hit_dict = _safe_parse_hit(hit, "from_memvid_hit")

        # DEBUG: Check if hit has direct attributes (not just dict keys)
        if hasattr(hit, '__dict__'):
            print(f"[METADATA DEBUG] Hit has __dict__: {list(hit.__dict__.keys())}")
        if hasattr(hit, '__slots__'):
            print(f"[METADATA DEBUG] Hit has __slots__: {hit.__slots__}")
        # Try to get all attributes
        if not isinstance(hit, dict):
            attrs = [attr for attr in dir(hit) if not attr.startswith('_')]
            print(f"[METADATA DEBUG] Hit attributes: {attrs[:20]}")  # First 20
        
        # Get the text field (for debug only - this is the fingerprint, not full content)
        text = hit_dict.get("text", hit_dict.get("snippet", ""))

        if _DEBUG_SDK_TYPES:
            print(f"\n[Librarian DEBUG] ========== SUPER-INDEX RETRIEVAL ==========")
            print(f"[Librarian DEBUG] Fingerprint (text field): {len(text)} chars")
            print(f"[Librarian DEBUG] Hit keys: {hit_dict.keys()}")

        # === PARSE METADATA ===
        # Try multiple ways to get metadata from the SDK
        raw_meta = None
        
        # Method 1: From hit_dict (standard dict access)
        raw_meta = hit_dict.get("metadata")
        
        # Method 2: Direct attribute access on hit object
        if raw_meta is None and hasattr(hit, 'metadata'):
            raw_meta = getattr(hit, 'metadata', None)
            print(f"[METADATA DEBUG] Got metadata from hit.metadata attribute: {type(raw_meta).__name__}")
        
        # Method 3: Check if metadata is nested in hit_dict under different keys
        if raw_meta is None:
            for key in ['metadata', 'meta', 'data', 'attrs', 'attributes', 'payload']:
                if key in hit_dict:
                    raw_meta = hit_dict[key]
                    print(f"[METADATA DEBUG] Found metadata in hit_dict['{key}']")
                    break
        
        # Method 4: Check if hit object has metadata as attribute with different name
        if raw_meta is None and not isinstance(hit, dict):
            for attr_name in ['metadata', 'meta', 'data', 'attrs', 'attributes']:
                if hasattr(hit, attr_name):
                    raw_meta = getattr(hit, attr_name, None)
                    if raw_meta is not None:
                        print(f"[METADATA DEBUG] Found metadata in hit.{attr_name} attribute")
                        break
        
        # DEBUG: Log what we found
        print(f"[METADATA DEBUG] ============================================")
        print(f"[METADATA DEBUG] hit_dict keys: {list(hit_dict.keys())}")
        print(f"[METADATA DEBUG] raw_meta type: {type(raw_meta).__name__ if raw_meta is not None else 'None'}")
        print(f"[METADATA DEBUG] raw_meta value (first 500): {str(raw_meta)[:500] if raw_meta is not None else 'None'}")
        print(f"[METADATA DEBUG] ============================================")
        
        meta = _safe_parse_metadata(raw_meta, "from_memvid_hit.metadata")

        if _DEBUG_SDK_TYPES:
            print(f"[Librarian DEBUG] Metadata keys: {meta.keys() if meta else 'None'}")

        # === SUPER-INDEX: READ FROM full_payload (PRIMARY METHOD) ===
        # This is the source of truth - complete, untruncated content
        user_message = ""
        ai_response = ""

        full_payload = meta.get("full_payload")
        if full_payload:
            # full_payload may be a dict or JSON string
            if isinstance(full_payload, str):
                try:
                    full_payload = json.loads(full_payload)
                except json.JSONDecodeError:
                    full_payload = None

            if isinstance(full_payload, dict):
                user_message = full_payload.get("user", "")
                ai_response = full_payload.get("ai", "")
                if _DEBUG_SDK_TYPES:
                    print(f"[Librarian DEBUG] SUCCESS: Read from full_payload")
                    print(f"[Librarian DEBUG]   user: {len(user_message)} chars")
                    print(f"[Librarian DEBUG]   ai: {len(ai_response)} chars")

        # === FALLBACK: Try legacy metadata fields ===
        if not user_message and not ai_response:
            user_message = meta.get("user_message", "") or meta.get("user", "")
            ai_response = meta.get("ai_response", "") or meta.get("ai", "")
            if user_message or ai_response:
                if _DEBUG_SDK_TYPES:
                    print(f"[Librarian DEBUG] FALLBACK: Read from legacy metadata fields")

        # === FALLBACK: Try parsing from serialized text (for very old data) ===
        if not user_message and not ai_response:
            import re
            if _DEBUG_SDK_TYPES:
                print(f"[Librarian DEBUG] FALLBACK: Trying to parse from serialized text")

            # Try regex extraction from SDK's serialized format
            user_match = re.search(r'"user":\s*"((?:[^"\\]|\\.)*)"', text)
            if user_match:
                user_message = user_match.group(1).replace('\\"', '"').replace('\\n', '\n')

            ai_match = re.search(r'"ai":\s*"((?:[^"\\]|\\.)*)"', text)
            if ai_match:
                ai_response = ai_match.group(1).replace('\\"', '"').replace('\\n', '\n')

        # === FINAL FALLBACK: Use fingerprint text as user message ===
        if not user_message and not ai_response:
            if _DEBUG_SDK_TYPES:
                print(f"[Librarian DEBUG] LAST RESORT: Using fingerprint as content")
            # Strip metadata suffix if present
            if " title:" in text:
                user_message = text.split(" title:")[0].strip()
            else:
                user_message = text

        if _DEBUG_SDK_TYPES:
            print(f"[Librarian DEBUG] FINAL: user={len(user_message)} chars, ai={len(ai_response)} chars")
            print(f"[Librarian DEBUG] ==========================================\n")

        # === PARSE OTHER METADATA ===
        tags = meta.get("tags", [])
        if isinstance(tags, str):
            try:
                tags = json.loads(tags)
            except:
                tags = [tags] if tags else []

        # Parse from label as fallback
        label = hit_dict.get("label", "")
        category = meta.get("category", "context")
        importance = meta.get("importance", "normal")
        status = meta.get("status", FrameStatus.ACTIVE.value)

        if label:
            for part in label.split("|"):
                if part.startswith("category:"):
                    category = part.replace("category:", "")
                elif part.startswith("importance:"):
                    importance = part.replace("importance:", "")
                elif part.startswith("status:"):
                    status = part.replace("status:", "")
                elif part.startswith("tag:"):
                    tag = part.replace("tag:", "")
                    if tag and tag not in tags:
                        tags.append(tag)

        # CRITICAL FIX: Read timestamp from Frame's timestamp field
        # The SDK stores the timestamp we passed via the timestamp parameter in the Frame's timestamp field
        # This is a Unix timestamp (int), so we need to convert it back to ISO format
        stored_timestamp = None
        stored_created_at_iso = None
        
        try:
            # Method 1: Read from Frame's timestamp field (top-level in hit_dict)
            # This is the primary source - the timestamp we passed via put(timestamp=...)
            frame_timestamp = hit_dict.get("timestamp")
            if frame_timestamp is not None:
                try:
                    # Convert Unix timestamp (int) to ISO string
                    if isinstance(frame_timestamp, (int, float)):
                        dt = datetime.fromtimestamp(frame_timestamp, tz=timezone.utc)
                        stored_created_at_iso = dt.isoformat()
                        stored_timestamp = frame_timestamp
                        print(f"[TIMESTAMP FIX] ✓ Found Frame timestamp: {frame_timestamp} -> ISO: {stored_created_at_iso}")
                    elif isinstance(frame_timestamp, str):
                        # Might already be ISO string
                        stored_created_at_iso = frame_timestamp
                        print(f"[TIMESTAMP FIX] Found Frame timestamp as string: {stored_created_at_iso}")
                except (ValueError, OSError, TypeError) as e:
                    print(f"[TIMESTAMP FIX] WARNING: Failed to convert timestamp {frame_timestamp!r}: {e}")
            
            # Method 2: Fallback to created_at field (for backward compatibility with old data)
            if stored_created_at_iso is None:
                created_at_value = hit_dict.get("created_at")
                if created_at_value is not None:
                    if isinstance(created_at_value, (int, float)):
                        try:
                            dt = datetime.fromtimestamp(created_at_value, tz=timezone.utc)
                            stored_created_at_iso = dt.isoformat()
                            print(f"[TIMESTAMP FIX] Found created_at as Unix timestamp: {created_at_value} -> ISO: {stored_created_at_iso}")
                        except (ValueError, OSError, TypeError):
                            pass
                    elif isinstance(created_at_value, str):
                        stored_created_at_iso = created_at_value
                        print(f"[TIMESTAMP FIX] Found created_at as string: {stored_created_at_iso}")
            
            # Method 3: Check metadata dict (for backward compatibility)
            if stored_created_at_iso is None and isinstance(meta, dict):
                meta_created_at = meta.get("created_at")
                if meta_created_at:
                    stored_created_at_iso = meta_created_at
                    print(f"[TIMESTAMP FIX] Found created_at in metadata dict: {stored_created_at_iso}")
            
            # Method 4: Direct attribute on hit object
            if stored_created_at_iso is None and hasattr(hit, 'timestamp'):
                attr_timestamp = getattr(hit, 'timestamp', None)
                if attr_timestamp is not None:
                    try:
                        if isinstance(attr_timestamp, (int, float)):
                            dt = datetime.fromtimestamp(attr_timestamp, tz=timezone.utc)
                            stored_created_at_iso = dt.isoformat()
                            print(f"[TIMESTAMP FIX] Found timestamp attribute: {attr_timestamp} -> ISO: {stored_created_at_iso}")
                    except (ValueError, OSError, TypeError):
                        pass
            
            # Final fallback: use current time
            effective_created_at = stored_created_at_iso if stored_created_at_iso else datetime.now(timezone.utc).isoformat()
            
            print(f"[TIMESTAMP FIX] ============================================")
            print(f"[TIMESTAMP FIX] Frame timestamp (Unix): {stored_timestamp}")
            print(f"[TIMESTAMP FIX] Effective created_at (ISO): {effective_created_at}")
            print(f"[TIMESTAMP FIX] ============================================")
        except Exception as e:
            # If timestamp parsing fails completely, use current time and log error
            print(f"[TIMESTAMP FIX] ERROR: Exception during timestamp parsing: {e}")
            import traceback
            traceback.print_exc()
            effective_created_at = datetime.now(timezone.utc).isoformat()

        return cls(
            id=hit_dict.get("title", hit_dict.get("frame_id", "")),
            user_message=user_message,
            ai_response=ai_response,
            tags=tags,
            category=category,
            importance=importance,
            emotional_tone=meta.get("emotional_tone"),
            created_at=effective_created_at,
            status=status,
            user_name=meta.get("user_name", "User"),
            thread_id=meta.get("thread_id"),
            message_index=meta.get("message_index"),
            word_count=meta.get("word_count", 0),
            model_id=model_id
        )

    def is_deleted(self) -> bool:
        """Check if this Pearl is soft-deleted."""
        return self.status == FrameStatus.DELETED.value

    def is_active(self) -> bool:
        """Check if this Pearl is active (retrievable)."""
        return self.status == FrameStatus.ACTIVE.value


@dataclass
class SearchResult:
    """A single search result from the vault."""
    pearl: Pearl
    score: float
    preview: str

    # Legacy compatibility
    @property
    def memory(self) -> MemoryEntry:
        """Convert Pearl to MemoryEntry for backward compatibility."""
        return MemoryEntry(
            id=self.pearl.id,
            content=self.pearl.full_content,
            category=self.pearl.category,
            importance=self.pearl.importance,
            tags=self.pearl.tags,
            created_at=self.pearl.created_at,
            source="vault"
        )

    def to_dict(self) -> dict:
        return {
            "pearl": self.pearl.to_dict(),
            "score": self.score,
            "preview": self.preview
        }


class MemvidStore:
    """
    The Librarian: Memory vault for a single AI model/persona.

    Stores FULL, RAW conversation exchanges (Pearls) without summarization.
    Uses metadata tags for indexing. Retrieval goes through the Synthesizer.

    Architecture:
    - Storage: Raw Pearls (complete exchanges)
    - Indexing: Metadata tags (#Theology, #Core, etc.)
    - Retrieval: Search → Raw Pearls → Synthesizer → Abstract
    - Deletion: Soft delete via status:deleted metadata
    """

    def __init__(
        self,
        model_id: str,
        vaults_dir: Optional[Path] = None,
        embedding_model: Optional[str] = None
    ):
        """
        Initialize or open the vault for a model.

        Args:
            model_id: The AI model/persona identifier (e.g., "eli", "opus")
            vaults_dir: Directory for vault files (default: config.VAULTS_DIR)
            embedding_model: Embedding model for vector search (default: bge-small-en-v1.5)
        """
        if not MEMVID_AVAILABLE:
            raise ImportError(
                "memvid-sdk is not installed. Install with:\n"
                "pip install memvid-sdk[fastembed]"
            )

        self.model_id = model_id
        self._safe_model_id = model_id.replace("/", "_").replace("\\", "_")

        # Embedding model for vector search (local fastembed)
        self.embedding_model = embedding_model or DEFAULT_EMBEDDING_MODEL

        # Set up vault directory
        if vaults_dir is None:
            from config import config
            vaults_dir = config.VAULTS_DIR
        self.vaults_dir = Path(vaults_dir)
        self.vaults_dir.mkdir(parents=True, exist_ok=True)

        # Vault file path
        self.vault_path = self.vaults_dir / f"{self._safe_model_id}.mv2"

        # Initialize the Memvid connection
        self._mv = None
        self._last_update: Optional[str] = None
        self._pearl_count: int = 0

        self._open_vault()

    def _open_vault(self):
        """Open or create the vault file with vector indexing enabled."""
        path_str = str(self.vault_path)

        # Embedding configuration for local HuggingFace embeddings
        # This enables hybrid search (lexical + semantic) without external API calls
        apikey_config = {
            "embedding": {
                "provider": "huggingface",
                "model": self.embedding_model
            }
        }

        try:
            if self.vault_path.exists():
                print(f"[Librarian] Opening vault: {self.vault_path}")
                print(f"[Librarian] Using embedding model: {self.embedding_model}")
                # Open existing vault with vector search enabled
                self._mv = memvid_use(
                    'basic',
                    path_str,
                    apikey=apikey_config,
                    enable_vec=True,
                    enable_lex=True
                )
            else:
                print(f"[Librarian] Creating new vault: {self.vault_path}")
                print(f"[Librarian] Embedding model: {self.embedding_model}")
                # Create new vault with vector + lexical indexing enabled
                self._mv = memvid_create(
                    path_str,
                    apikey=apikey_config,
                    enable_vec=True,
                    enable_lex=True
                )

            self._refresh_stats()
        except Exception as e:
            print(f"[Librarian] Error opening vault: {e}")
            raise

    def _refresh_stats(self):
        """Refresh internal statistics from the vault."""
        try:
            if self._mv and hasattr(self._mv, 'stats'):
                stats = self._mv.stats()
                self._pearl_count = stats.get('document_count', 0)
            self._last_update = datetime.now().isoformat()
        except Exception as e:
            print(f"[Librarian] Warning: Could not refresh stats: {e}")

    def close(self):
        """Close the vault connection."""
        if self._mv and hasattr(self._mv, 'seal'):
            try:
                self._mv.seal()
            except Exception as e:
                print(f"[Librarian] Warning: Error closing vault: {e}")
        self._mv = None

    # =========================================================================
    # STORAGE: Add Raw Pearls (Full Conversation Exchanges)
    # =========================================================================

    def add_pearl(
        self,
        user_message: str,
        ai_response: str,
        tags: Optional[List[str]] = None,
        category: str = "context",
        importance: str = "normal",
        emotional_tone: Optional[str] = None,
        created_at: Optional[str] = None,
        user_name: str = "User",
        thread_id: Optional[str] = None,
        message_index: Optional[int] = None,
        pearl_id: Optional[str] = None
    ) -> str:
        """
        Add a complete conversation exchange (Pearl) to the vault.

        SUPER-INDEX ARCHITECTURE:
        - INDEX (text field): Compact "Fingerprint" for embedding/search
          - Short conversations: full text
          - Long conversations: LLM-generated summary + keywords
        - VAULT (metadata.full_payload): Complete, untruncated conversation

        This ensures:
        1. Semantic search works efficiently (fingerprint fits embedding context)
        2. Full fidelity retrieval (complete text in metadata, never truncated)

        Args:
            user_message: The complete user input (may be 3+ pages)
            ai_response: The complete AI response
            tags: Metadata tags for indexing (#Theology, #Core, etc.)
            category: Category for organization
            importance: Importance level (core, high, normal, low)
            emotional_tone: Emotional context of the exchange
            created_at: Original timestamp (ISO format) - PRESERVED!
            user_name: User's name for the transcript
            thread_id: Optional thread/conversation ID
            message_index: Position in the conversation thread
            pearl_id: Optional explicit ID (auto-generated if not provided)

        Returns:
            The Pearl ID
        """
        # Generate ID if not provided
        if not pearl_id:
            pearl_id = f"pearl_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}"

        # DEBUG: Log the created_at value being used
        effective_created_at = created_at if created_at else datetime.now().isoformat()
        print(f"[TIMESTAMP DEBUG] ============================================")
        print(f"[TIMESTAMP DEBUG] add_pearl received created_at param: {created_at!r}")
        print(f"[TIMESTAMP DEBUG] effective_created_at will be: {effective_created_at!r}")

        pearl = Pearl(
            id=pearl_id,
            user_message=user_message,
            ai_response=ai_response,
            tags=tags or [],
            category=category,
            importance=importance,
            emotional_tone=emotional_tone,
            created_at=effective_created_at,
            status=FrameStatus.ACTIVE.value,
            user_name=user_name,
            thread_id=thread_id,
            message_index=message_index,
            model_id=self.model_id
        )

        print(f"[TIMESTAMP DEBUG] Pearl object created_at: {pearl.created_at!r}")

        # === SUPER-INDEX: Build fingerprint for vector search ===
        # The fingerprint is compact enough for embedding models
        # Full content is stored in metadata.full_payload
        fingerprint = build_fingerprint(user_message, ai_response)

        if _DEBUG_SDK_TYPES:
            print(f"[Librarian] Fingerprint: {len(fingerprint)} chars (original: {pearl.word_count} words)")

        # Get metadata and verify created_at is included
        metadata_to_store = pearl.get_metadata()
        print(f"[TIMESTAMP DEBUG] Metadata to store - created_at: {metadata_to_store.get('created_at')!r}")
        print(f"[TIMESTAMP DEBUG] Metadata keys: {list(metadata_to_store.keys())}")
        print(f"[TIMESTAMP DEBUG] ============================================")

        # Convert ISO timestamp to Unix timestamp (int) for SDK's timestamp parameter
        # The SDK's timestamp parameter sets the Frame's top-level timestamp field
        timestamp_int = None
        if effective_created_at:
            try:
                # Parse ISO string and convert to Unix timestamp
                dt = datetime.fromisoformat(effective_created_at.replace('Z', '+00:00'))
                timestamp_int = int(dt.timestamp())
                print(f"[TIMESTAMP DEBUG] Converted ISO '{effective_created_at}' to Unix timestamp: {timestamp_int}")
            except (ValueError, AttributeError) as e:
                print(f"[TIMESTAMP DEBUG] WARNING: Failed to convert timestamp '{effective_created_at}': {e}")
                print(f"[TIMESTAMP DEBUG] Will use current time instead")
                timestamp_int = int(datetime.now().timestamp())

        # Store in Memvid
        # - text: fingerprint (for embedding/search)
        # - metadata: full_payload + indexing metadata (for retrieval)
        # - timestamp: Original conversation timestamp (Unix int) - CRITICAL FIX!
        # DEBUG: Verify metadata before storing
        print(f"[TIMESTAMP DEBUG] About to store - metadata type: {type(metadata_to_store).__name__}")
        print(f"[TIMESTAMP DEBUG] About to store - metadata keys: {list(metadata_to_store.keys())}")
        print(f"[TIMESTAMP DEBUG] About to store - timestamp parameter: {timestamp_int}")
        
        self._mv.put(
            title=pearl.id,
            label=pearl.get_label(),
            metadata=metadata_to_store,
            text=fingerprint,  # Compact fingerprint for embedding
            timestamp=timestamp_int  # CRITICAL: Pass original timestamp to SDK's timestamp parameter
        )
        
        print(f"[TIMESTAMP DEBUG] Storage complete for pearl {pearl.id} with timestamp={timestamp_int}")

        self._pearl_count += 1
        self._last_update = datetime.now().isoformat()

        tag_str = ", ".join(tags[:3]) if tags else "none"
        print(f"[Librarian] Stored Pearl [{pearl.id}] {pearl.word_count} words, tags: {tag_str}")
        return pearl.id

    def add_pearl_object(self, pearl: Pearl) -> str:
        """
        Add a pre-constructed Pearl to the vault.

        Uses Super-Index architecture: fingerprint for search, full_payload for retrieval.
        """
        pearl.model_id = self.model_id

        # Build fingerprint for this pearl
        fingerprint = build_fingerprint(pearl.user_message, pearl.ai_response)

        # Convert ISO timestamp to Unix timestamp (int) for SDK's timestamp parameter
        timestamp_int = None
        if pearl.created_at:
            try:
                dt = datetime.fromisoformat(pearl.created_at.replace('Z', '+00:00'))
                timestamp_int = int(dt.timestamp())
            except (ValueError, AttributeError):
                timestamp_int = int(datetime.now().timestamp())

        self._mv.put(
            title=pearl.id,
            label=pearl.get_label(),
            metadata=pearl.get_metadata(),
            text=fingerprint,
            timestamp=timestamp_int  # CRITICAL: Pass original timestamp to SDK's timestamp parameter
        )

        self._pearl_count += 1
        self._last_update = datetime.now().isoformat()

        return pearl.id

    def add_many_pearls(self, pearls: List[Pearl]) -> List[str]:
        """Batch add multiple Pearls efficiently using Super-Index architecture."""
        if not pearls:
            return []

        batch = []
        for pearl in pearls:
            pearl.model_id = self.model_id
            fingerprint = build_fingerprint(pearl.user_message, pearl.ai_response)
            
            # Convert ISO timestamp to Unix timestamp (int) for SDK's timestamp parameter
            timestamp_int = None
            if pearl.created_at:
                try:
                    dt = datetime.fromisoformat(pearl.created_at.replace('Z', '+00:00'))
                    timestamp_int = int(dt.timestamp())
                except (ValueError, AttributeError):
                    timestamp_int = int(datetime.now().timestamp())
            
            batch.append({
                "title": pearl.id,
                "label": pearl.get_label(),
                "metadata": pearl.get_metadata(),
                "text": fingerprint,  # Use fingerprint, not full_content
                "timestamp": timestamp_int  # CRITICAL: Pass original timestamp
            })

        if hasattr(self._mv, 'put_many'):
            self._mv.put_many(batch)
        else:
            for item in batch:
                self._mv.put(**item)

        self._pearl_count += len(pearls)
        self._last_update = datetime.now().isoformat()

        print(f"[Librarian] Batch stored {len(pearls)} Pearls")
        return [p.id for p in pearls]

    # =========================================================================
    # LEGACY COMPATIBILITY: add_memory wraps add_pearl
    # =========================================================================

    def add_memory(
        self,
        content: str,
        category: str = "context",
        importance: str = "normal",
        tags: Optional[List[str]] = None,
        user_id: Optional[str] = None,
        source: str = "conversation",
        created_at: Optional[str] = None,
        ai_self_type: Optional[str] = None,
        supersedes: Optional[str] = None,
        emotional_tone: Optional[str] = None,
        memory_id: Optional[str] = None
    ) -> str:
        """
        Legacy compatibility: Add a memory (converts to Pearl format).

        For new code, use add_pearl() directly.
        """
        # Parse content into user_message and ai_response if possible
        user_message = content
        ai_response = ""

        if "\nAI:" in content or "\nAI responded:" in content:
            # Try to split into user/AI parts
            for splitter in ["\nAI:", "\nAI responded:", "\n\nAI:"]:
                if splitter in content:
                    parts = content.split(splitter, 1)
                    user_message = parts[0].replace("User:", "").replace("User said:", "").strip()
                    ai_response = parts[1].strip()
                    break

        return self.add_pearl(
            user_message=user_message,
            ai_response=ai_response,
            tags=tags or [],
            category=category,
            importance=importance,
            emotional_tone=emotional_tone,
            created_at=created_at,
            pearl_id=memory_id
        )

    def add_memory_entry(self, entry: MemoryEntry) -> str:
        """Legacy compatibility: Add a MemoryEntry (converts to Pearl)."""
        return self.add_memory(
            content=entry.content,
            category=entry.category,
            importance=entry.importance,
            tags=entry.tags,
            created_at=entry.created_at,
            emotional_tone=entry.emotional_tone,
            memory_id=entry.id
        )

    def add_many(self, entries: List[MemoryEntry]) -> List[str]:
        """Legacy compatibility: Batch add MemoryEntries."""
        return [self.add_memory_entry(e) for e in entries]

    # =========================================================================
    # SOFT DELETE: Mark Pearls as deleted without removing
    # =========================================================================

    def soft_delete(self, pearl_id: str, reason: Optional[str] = None) -> bool:
        """
        Soft delete a Pearl by adding a deletion marker.

        In append-only storage, we add a new record marking the old one deleted.
        The original content is preserved but excluded from search results.

        Args:
            pearl_id: ID of the Pearl to delete
            reason: Optional reason for deletion

        Returns:
            True if deletion marker was added
        """
        try:
            # Add a deletion marker frame
            deletion_id = f"delete_{pearl_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

            # Use current time for deletion marker timestamp
            deletion_timestamp = int(datetime.now().timestamp())
            
            self._mv.put(
                title=deletion_id,
                label=f"deletion_marker|target:{pearl_id}|status:deleted",
                metadata={
                    "type": "deletion_marker",
                    "target_pearl_id": pearl_id,
                    "deleted_at": datetime.now().isoformat(),
                    "reason": reason or "user_requested"
                },
                text=f"DELETION MARKER: Pearl {pearl_id} has been soft-deleted. Reason: {reason or 'user requested'}",
                timestamp=deletion_timestamp  # Use current time for deletion marker
            )

            print(f"[Librarian] Soft deleted Pearl: {pearl_id}")
            return True

        except Exception as e:
            print(f"[Librarian] Error soft-deleting Pearl {pearl_id}: {e}")
            return False

    def get_deleted_pearl_ids(self) -> set:
        """Get set of all soft-deleted Pearl IDs."""
        deleted_ids = set()

        try:
            # Search for deletion markers
            result = self._mv.find("deletion_marker", k=1000, mode="lex")
            hits = _extract_hits_from_result(result, "get_deleted_pearl_ids")

            for hit in hits:
                hit_dict = _safe_parse_hit(hit, "get_deleted_pearl_ids.hit")
                label = hit_dict.get("label", "")
                if "deletion_marker" in label:
                    # Extract target pearl ID
                    for part in label.split("|"):
                        if part.startswith("target:"):
                            deleted_ids.add(part.replace("target:", ""))

        except Exception as e:
            print(f"[Librarian] Error getting deleted IDs: {e}")

        return deleted_ids

    # =========================================================================
    # SEARCH: Find relevant Pearls (for Synthesizer)
    # =========================================================================

    def search_pearls(
        self,
        query: str,
        limit: int = 10,
        mode: str = "hybrid",
        include_deleted: bool = False
    ) -> List[SearchResult]:
        """
        Search for relevant Pearls (complete conversation exchanges).

        These raw Pearls should be passed to the Synthesizer for abstraction
        before being injected into the prompt context.

        Args:
            query: The search query
            limit: Maximum results to return
            mode: Search mode - "hybrid" (default), "lex", "sem"
            include_deleted: Whether to include soft-deleted Pearls

        Returns:
            List of SearchResult objects with full Pearls
        """
        if not query.strip():
            return []

        try:
            # Get deleted IDs to filter
            deleted_ids = set() if include_deleted else self.get_deleted_pearl_ids()

            memvid_mode = {
                "hybrid": None,
                "lex": "lex",
                "lexical": "lex",
                "sem": "sem",
                "semantic": "sem",
                "vector": "sem"
            }.get(mode.lower())

            if memvid_mode:
                find_result = self._mv.find(query, k=limit * 2, mode=memvid_mode)
            else:
                find_result = self._mv.find(query, k=limit * 2)

            hits = _extract_hits_from_result(find_result, "search_pearls")

            results = []
            for hit in hits:
                hit_dict = _safe_parse_hit(hit, "search_pearls.hit")

                # Skip deletion markers
                label = hit_dict.get("label", "")
                if "deletion_marker" in label:
                    continue

                pearl = Pearl.from_memvid_hit(hit_dict, self.model_id)

                # Skip deleted pearls
                if pearl.id in deleted_ids:
                    continue

                # Skip non-active status
                if not include_deleted and not pearl.is_active():
                    continue

                results.append(SearchResult(
                    pearl=pearl,
                    score=hit.get("score", 0.0),
                    preview=hit.get("preview", pearl.full_content[:200])
                ))

                if len(results) >= limit:
                    break

            return results

        except Exception as e:
            print(f"[Librarian] Search error: {e}")
            return []

    def search(
        self,
        query: str,
        limit: int = 10,
        mode: str = "hybrid",
        exclude_archived: bool = True
    ) -> List[SearchResult]:
        """Legacy compatibility: Alias for search_pearls."""
        return self.search_pearls(query, limit, mode, include_deleted=not exclude_archived)

    def get_pearls_by_tag(self, tag: str, limit: int = 50) -> List[Pearl]:
        """Get Pearls with a specific tag."""
        try:
            # Search for tag in label
            find_result = self._mv.find(f"tag:{tag}", k=limit * 2, mode="lex")
            hits = _extract_hits_from_result(find_result, "get_pearls_by_tag")
            deleted_ids = self.get_deleted_pearl_ids()

            results = []
            for hit in hits:
                hit_dict = _safe_parse_hit(hit, "get_pearls_by_tag.hit")
                if "deletion_marker" in hit_dict.get("label", ""):
                    continue

                pearl = Pearl.from_memvid_hit(hit_dict, self.model_id)

                if pearl.id in deleted_ids:
                    continue

                if tag in pearl.tags or f"#{tag}" in pearl.tags:
                    results.append(pearl)

                if len(results) >= limit:
                    break

            return results

        except Exception as e:
            print(f"[Librarian] Error getting tag {tag}: {e}")
            return []

    def get_core_pearls(self) -> List[Pearl]:
        """Get all core (always-included) Pearls."""
        try:
            find_result = self._mv.find("importance:core", k=100, mode="lex")
            hits = _extract_hits_from_result(find_result, "get_core_pearls")
            deleted_ids = self.get_deleted_pearl_ids()

            results = []
            for hit in hits:
                hit_dict = _safe_parse_hit(hit, "get_core_pearls.hit")
                label = hit_dict.get("label", "")
                if "importance:core" in label and "deletion_marker" not in label:
                    title = hit_dict.get("title", "")
                    if title not in deleted_ids:
                        results.append(Pearl.from_memvid_hit(hit_dict, self.model_id))
            return results
        except Exception as e:
            print(f"[Librarian] Error getting core Pearls: {e}")
            return []

    def get_by_category(self, category: str, limit: int = 50) -> List[MemoryEntry]:
        """Legacy compatibility: Get memories by category."""
        try:
            find_result = self._mv.find(f"category:{category}", k=limit, mode="lex")
            hits = _extract_hits_from_result(find_result, "get_by_category")
            deleted_ids = self.get_deleted_pearl_ids()

            entries = []
            for hit in hits:
                hit_dict = _safe_parse_hit(hit, "get_by_category.hit")
                label = hit_dict.get("label", "")
                if "deletion_marker" in label:
                    continue
                if f"category:{category}" not in label:
                    continue
                if hit_dict.get("title", "") in deleted_ids:
                    continue

                pearl = Pearl.from_memvid_hit(hit_dict, self.model_id)
                entries.append(MemoryEntry(
                    id=pearl.id,
                    content=pearl.full_content,
                    category=pearl.category,
                    importance=pearl.importance,
                    tags=pearl.tags,
                    created_at=pearl.created_at
                ))

            return entries

        except Exception as e:
            print(f"[Librarian] Error getting category {category}: {e}")
            return []

    def get_by_importance(self, importance: str, limit: int = 50) -> List[MemoryEntry]:
        """Legacy compatibility: Get memories by importance."""
        try:
            find_result = self._mv.find(f"importance:{importance}", k=limit, mode="lex")
            hits = _extract_hits_from_result(find_result, "get_by_importance")
            deleted_ids = self.get_deleted_pearl_ids()

            entries = []
            for hit in hits:
                hit_dict = _safe_parse_hit(hit, "get_by_importance.hit")
                label = hit_dict.get("label", "")
                if "deletion_marker" in label:
                    continue
                if f"importance:{importance}" not in label:
                    continue
                if hit_dict.get("title", "") in deleted_ids:
                    continue

                pearl = Pearl.from_memvid_hit(hit_dict, self.model_id)
                entries.append(MemoryEntry(
                    id=pearl.id,
                    content=pearl.full_content,
                    category=pearl.category,
                    importance=pearl.importance,
                    tags=pearl.tags,
                    created_at=pearl.created_at
                ))

            return entries

        except Exception as e:
            print(f"[Librarian] Error getting importance {importance}: {e}")
            return []

    def get_core_memories(self) -> List[MemoryEntry]:
        """Legacy compatibility: Get core memories."""
        pearls = self.get_core_pearls()
        return [
            MemoryEntry(
                id=p.id,
                content=p.full_content,
                category=p.category,
                importance=p.importance,
                tags=p.tags,
                created_at=p.created_at
            )
            for p in pearls
        ]

    def get_ai_self_memories(self, include_archived: bool = False) -> List[MemoryEntry]:
        """Legacy compatibility: Get AI self memories."""
        return self.get_by_category(MemoryCategory.AI_SELF.value, limit=200)

    def get_ai_self_by_type(self, ai_self_type: str) -> List[MemoryEntry]:
        """Legacy compatibility: Get AI self memories by type."""
        all_ai_self = self.get_ai_self_memories()
        return [m for m in all_ai_self if ai_self_type in m.tags]

    def get_recent_pearls(self, limit: int = 50) -> List[Pearl]:
        """
        Get most recent Pearls (returns Pearl objects, not MemoryEntry).
        
        This method searches across all categories to ensure we get ALL Pearls,
        not just search results.
        """
        try:
            print(f"[get_recent_pearls] Starting retrieval for model={self.model_id}, limit={limit}")
            deleted_ids = self.get_deleted_pearl_ids()
            print(f"[get_recent_pearls] Deleted IDs count: {len(deleted_ids)}")
            hits = []

            # SKIP timeline() - it returns hits without metadata/text fields
            # Instead, use category search which returns full hits with metadata
            # Try timeline first (most efficient) - BUT SKIP IT because it doesn't return metadata
            # if hasattr(self._mv, 'timeline'):
            #     try:
            #         print(f"[get_recent_pearls] Trying timeline()...")
            #         result = self._mv.timeline(limit=limit * 2)
            #         hits = _extract_hits_from_result(result, "get_recent_pearls.timeline")
            #         print(f"[get_recent_pearls] Timeline returned {len(hits)} hits")
            #     except Exception as timeline_err:
            #         err_str = str(timeline_err)
            #         print(f"[get_recent_pearls] Timeline error: {err_str}")
            #         if "MV005" in err_str:
            #             # MV005: Vault too small for timeline - fall through
            #             if _DEBUG_SDK_TYPES:
            #                 print(f"[Librarian DEBUG] MV005 ignored: Vault too small for timeline")
            #         else:
            #             raise

            # Use the same approach as export() - search by category with find()
            # This is the proven method that works in export()
            print(f"[get_recent_pearls] Using export() method: searching by category...")
            all_hits = []
            from memory_entry import MemoryCategory
            print(f"[get_recent_pearls] MemoryCategory values: {[cat.value for cat in MemoryCategory]}")
            
            for cat in MemoryCategory:
                try:
                    # Use exact same query format as export()
                    query = f"category:{cat.value}"
                    print(f"[get_recent_pearls] Searching with query: {query}")
                    find_result = self._mv.find(query, k=limit * 10, mode="lex")
                    cat_hits = _extract_hits_from_result(find_result, f"get_recent_pearls.category.{cat.value}")
                    print(f"[get_recent_pearls] Category {cat.value} returned {len(cat_hits)} hits")
                    
                    if cat_hits:
                        # Debug first hit to see structure
                        first_hit = _safe_parse_hit(cat_hits[0], "debug")
                        print(f"[get_recent_pearls] First hit keys: {list(first_hit.keys())}")
                        print(f"[get_recent_pearls] First hit has metadata: {'metadata' in first_hit}")
                        print(f"[get_recent_pearls] First hit has title: {'title' in first_hit}")
                        print(f"[get_recent_pearls] First hit label: {first_hit.get('label', 'NO LABEL')[:200]}")
                        # Check if metadata has full_payload
                        meta = first_hit.get('metadata', {})
                        if isinstance(meta, dict):
                            print(f"[get_recent_pearls] First hit metadata keys: {list(meta.keys())}")
                            print(f"[get_recent_pearls] First hit has full_payload: {'full_payload' in meta}")
                    
                    all_hits.extend(cat_hits)
                except Exception as e:
                    print(f"[get_recent_pearls] Error searching category {cat.value}: {e}")
                    import traceback
                    traceback.print_exc()
                    pass
            
            hits = all_hits
            print(f"[get_recent_pearls] Total category hits: {len(hits)}")
            
            # ALWAYS try status:active search as well to catch any pearls that don't match categories
            # This ensures we get ALL active pearls, not just those matching category queries
            print(f"[get_recent_pearls] Also searching by status:active to catch any missed pearls...")
            try:
                find_result = self._mv.find("status:active", k=limit * 10, mode="lex")
                status_hits = _extract_hits_from_result(find_result, "get_recent_pearls.status")
                print(f"[get_recent_pearls] Status:active search returned {len(status_hits)} hits")
                # Add status hits to the collection (deduplication will handle duplicates)
                hits.extend(status_hits)
                print(f"[get_recent_pearls] Total hits after adding status:active: {len(hits)}")
            except Exception as e:
                print(f"[get_recent_pearls] Status search error: {e}")
            
            # ALSO search by title prefix "pearl_" to catch ANY pearls that might not match category/status
            # This is a fallback to ensure we don't miss any pearls due to indexing issues
            print(f"[get_recent_pearls] Also searching by title prefix 'pearl_' to catch any missed pearls...")
            try:
                # Try searching for "pearl_" which should match all pearl titles
                find_result = self._mv.find("pearl_", k=limit * 10, mode="lex")
                title_hits = _extract_hits_from_result(find_result, "get_recent_pearls.title_prefix")
                print(f"[get_recent_pearls] Title prefix search ('pearl_') returned {len(title_hits)} hits")
                # Add title hits to the collection (deduplication will handle duplicates)
                hits.extend(title_hits)
                print(f"[get_recent_pearls] Total hits after adding title prefix search: {len(hits)}")
            except Exception as e:
                print(f"[get_recent_pearls] Title prefix search error: {e}")
            
            # If still no hits, try a very broad search to see what's actually in the vault
            if not hits:
                print(f"[get_recent_pearls] No category hits! Trying broad searches to debug...")
                
                # Try searching by status:active
                try:
                    find_result = self._mv.find("status:active", k=limit * 10, mode="lex")
                    status_hits = _extract_hits_from_result(find_result, "get_recent_pearls.status")
                    print(f"[get_recent_pearls] Status:active search returned {len(status_hits)} hits")
                    if status_hits:
                        first_hit = _safe_parse_hit(status_hits[0], "debug")
                        print(f"[get_recent_pearls] First status hit keys: {list(first_hit.keys())}")
                        print(f"[get_recent_pearls] First status hit label: {first_hit.get('label', 'NO LABEL')[:200]}")
                    hits = status_hits
                except Exception as e:
                    print(f"[get_recent_pearls] Status search error: {e}")
                
                # If still nothing, try searching for any text (very broad)
                if not hits:
                    try:
                        # Try searching for common words that might be in fingerprints
                        find_result = self._mv.find("the", k=limit * 10, mode="lex")
                        broad_hits = _extract_hits_from_result(find_result, "get_recent_pearls.broad")
                        print(f"[get_recent_pearls] Broad search ('the') returned {len(broad_hits)} hits")
                        if broad_hits:
                            first_hit = _safe_parse_hit(broad_hits[0], "debug")
                            print(f"[get_recent_pearls] First broad hit label: {first_hit.get('label', 'NO LABEL')[:200]}")
                        hits = broad_hits
                    except Exception as e:
                        print(f"[get_recent_pearls] Broad search error: {e}")

            print(f"[get_recent_pearls] Total hits before filtering: {len(hits)}")
            
            # DEBUG: Log all titles to see if missing pearl is in the hits
            print(f"[get_recent_pearls] DEBUG: Checking all hit titles for missing pearl...")
            all_titles = []
            for hit in hits:
                hit_dict = _safe_parse_hit(hit, "get_recent_pearls.debug_title")
                title = hit_dict.get("title", "")
                if title:
                    all_titles.append(title)
            print(f"[get_recent_pearls] DEBUG: Found {len(all_titles)} titles in hits")
            if "pearl_20260201_121309_203341" in all_titles:
                print(f"[get_recent_pearls] *** FOUND MISSING PEARL IN HITS! ***")
            else:
                print(f"[get_recent_pearls] *** MISSING PEARL NOT IN HITS ***")
                print(f"[get_recent_pearls] DEBUG: Sample titles: {sorted(all_titles)[:5]}")
            
            pearls = []
            seen_ids = set()  # Deduplicate
            skipped_deletion_markers = 0
            skipped_no_id = 0
            skipped_deleted = 0
            skipped_duplicates = 0
            
            for hit in hits:
                hit_dict = _safe_parse_hit(hit, "get_recent_pearls.hit")
                label = hit_dict.get("label", "")
                if "deletion_marker" in label:
                    skipped_deletion_markers += 1
                    continue
                
                # DEBUG: Check what ID fields are available
                title_val = hit_dict.get("title")
                frame_id_val = hit_dict.get("frame_id")
                
                # Get pearl ID - can be in 'title' or 'frame_id' field
                pearl_id = hit_dict.get("title") or hit_dict.get("frame_id", "")
                
                # Special debug for the missing pearl
                if pearl_id == "pearl_20260201_121309_203341":
                    print(f"[get_recent_pearls] *** FOUND MISSING PEARL ***")
                    print(f"[get_recent_pearls]   title={repr(title_val)}, frame_id={repr(frame_id_val)}")
                    print(f"[get_recent_pearls]   extracted pearl_id={repr(pearl_id)}")
                    print(f"[get_recent_pearls]   in deleted_ids: {pearl_id in deleted_ids}")
                    print(f"[get_recent_pearls]   in seen_ids: {pearl_id in seen_ids}")
                    print(f"[get_recent_pearls]   hit_dict keys: {list(hit_dict.keys())}")
                
                if not pearl_id:
                    skipped_no_id += 1
                    print(f"[get_recent_pearls] WARNING: Hit has no title or frame_id, skipping")
                    print(f"[get_recent_pearls] Hit keys: {list(hit_dict.keys())}")
                    continue
                    
                if pearl_id in deleted_ids:
                    skipped_deleted += 1
                    if pearl_id == "pearl_20260201_121309_203341":
                        print(f"[get_recent_pearls] *** MISSING PEARL FILTERED: DELETED ***")
                    print(f"[get_recent_pearls] Skipping deleted pearl: {pearl_id}")
                    continue
                if pearl_id in seen_ids:
                    skipped_duplicates += 1
                    if pearl_id == "pearl_20260201_121309_203341":
                        print(f"[get_recent_pearls] *** MISSING PEARL FILTERED: DUPLICATE ***")
                    print(f"[get_recent_pearls] Skipping duplicate pearl: {pearl_id}")
                    continue
                seen_ids.add(pearl_id)
                
                if pearl_id == "pearl_20260201_121309_203341":
                    print(f"[get_recent_pearls] *** MISSING PEARL ADDED TO RESULTS ***")

                pearl = Pearl.from_memvid_hit(hit_dict, self.model_id)
                pearls.append(pearl)
                print(f"[get_recent_pearls] Added pearl {pearl_id}, user_msg_len={len(pearl.user_message)}, ai_msg_len={len(pearl.ai_response)}")

            print(f"[get_recent_pearls] FILTERING SUMMARY:")
            print(f"[get_recent_pearls]   Total hits: {len(hits)}")
            print(f"[get_recent_pearls]   Skipped deletion markers: {skipped_deletion_markers}")
            print(f"[get_recent_pearls]   Skipped (no ID): {skipped_no_id}")
            print(f"[get_recent_pearls]   Skipped (deleted): {skipped_deleted}")
            print(f"[get_recent_pearls]   Skipped (duplicates): {skipped_duplicates}")
            print(f"[get_recent_pearls]   Valid pearls: {len(pearls)}")
            print(f"[get_recent_pearls]   Unique pearl IDs found: {sorted(list(seen_ids))}")
            
            print(f"[get_recent_pearls] Total pearls before sorting: {len(pearls)}")
            # Sort by created_at (most recent first)
            pearls.sort(key=lambda p: p.created_at or "", reverse=True)
            result = pearls[:limit]
            print(f"[get_recent_pearls] After limit ({limit}): {len(result)} pearls")
            print(f"[get_recent_pearls] Returning {len(result)} pearls")
            return result

        except Exception as e:
            if "MV005" in str(e):
                if _DEBUG_SDK_TYPES:
                    print(f"[Librarian DEBUG] MV005 ignored: Vault too small for timeline")
                return []
            print(f"[Librarian] Error getting recent pearls: {e}")
            import traceback
            traceback.print_exc()
            return []

    def get_recent(self, limit: int = 10) -> List[MemoryEntry]:
        """Get most recent memories."""
        try:
            deleted_ids = self.get_deleted_pearl_ids()
            hits = []

            # Try timeline first, with specific handling for MV005 (vault too small)
            if hasattr(self._mv, 'timeline'):
                try:
                    result = self._mv.timeline(limit=limit * 2)
                    hits = _extract_hits_from_result(result, "get_recent.timeline")
                except Exception as timeline_err:
                    err_str = str(timeline_err)
                    if "MV005" in err_str:
                        # MV005: Time index track is invalid - vault too small for timeline
                        if _DEBUG_SDK_TYPES:
                            print(f"[Librarian DEBUG] MV005 ignored: Vault too small for timeline")
                        # Fall through to category-based search
                    else:
                        # Re-raise unexpected errors
                        raise

            # Fallback: Search across all categories (like export() does) to get ALL Pearls
            if not hits:
                all_hits = []
                from memory_entry import MemoryCategory
                for cat in MemoryCategory:
                    try:
                        find_result = self._mv.find(f"category:{cat.value}", k=limit * 10, mode="lex")
                        cat_hits = _extract_hits_from_result(find_result, f"get_recent.category.{cat.value}")
                        all_hits.extend(cat_hits)
                    except Exception:
                        pass
                hits = all_hits

            # If still no hits, try empty string search as last resort
            if not hits:
                try:
                    result = self._mv.find("", k=limit * 3, mode="lex")
                    hits = _extract_hits_from_result(result, "get_recent.find")
                except Exception:
                    pass

            entries = []
            seen_ids = set()  # Deduplicate
            for hit in hits:
                hit_dict = _safe_parse_hit(hit, "get_recent.hit")
                label = hit_dict.get("label", "")
                if "deletion_marker" in label:
                    continue
                
                pearl_id = hit_dict.get("title", "")
                if pearl_id in deleted_ids or pearl_id in seen_ids:
                    continue
                seen_ids.add(pearl_id)

                pearl = Pearl.from_memvid_hit(hit_dict, self.model_id)
                entries.append(MemoryEntry(
                    id=pearl.id,
                    content=pearl.full_content,
                    category=pearl.category,
                    importance=pearl.importance,
                    tags=pearl.tags,
                    created_at=pearl.created_at
                ))

            entries.sort(key=lambda e: e.created_at or "", reverse=True)
            return entries[:limit]

        except Exception as e:
            # Check for MV005 at top level too (defensive)
            if "MV005" in str(e):
                if _DEBUG_SDK_TYPES:
                    print(f"[Librarian DEBUG] MV005 ignored: Vault too small for timeline")
                return []
            print(f"[Librarian] Error getting recent: {e}")
            import traceback
            traceback.print_exc()
            return []

    def get_by_tag(self, tag: str, limit: int = 50) -> List[MemoryEntry]:
        """Legacy compatibility: Get memories by tag."""
        pearls = self.get_pearls_by_tag(tag, limit)
        return [
            MemoryEntry(
                id=p.id,
                content=p.full_content,
                category=p.category,
                importance=p.importance,
                tags=p.tags,
                created_at=p.created_at
            )
            for p in pearls
        ]

    # =========================================================================
    # RAW PEARL RETRIEVAL (for Synthesizer)
    # =========================================================================

    def get_raw_pearls_for_synthesis(
        self,
        query: str,
        limit: int = 5
    ) -> List[Pearl]:
        """
        Get raw Pearls for the Synthesizer to process.

        This is the key method for the Librarian architecture:
        1. Search finds relevant Pearls
        2. Return full, raw content
        3. Caller passes to Synthesizer for abstraction

        Args:
            query: Search query
            limit: Maximum Pearls to return

        Returns:
            List of full Pearl objects with complete content
        """
        results = self.search_pearls(query, limit=limit, mode="hybrid")
        return [r.pearl for r in results]

    def get_thread_pearls(self, thread_id: str) -> List[Pearl]:
        """Get all Pearls from a specific conversation thread."""
        try:
            find_result = self._mv.find(f"thread:{thread_id}", k=100, mode="lex")
            hits = _extract_hits_from_result(find_result, "get_thread_pearls")
            deleted_ids = self.get_deleted_pearl_ids()

            pearls = []
            for hit in hits:
                hit_dict = _safe_parse_hit(hit, "get_thread_pearls.hit")
                label = hit_dict.get("label", "")
                if "deletion_marker" in label:
                    continue

                meta = _safe_parse_metadata(hit_dict.get("metadata", {}), "get_thread_pearls.metadata")
                if meta.get("thread_id") != thread_id:
                    continue

                if hit_dict.get("title", "") in deleted_ids:
                    continue

                pearls.append(Pearl.from_memvid_hit(hit_dict, self.model_id))

            # Sort by message index
            pearls.sort(key=lambda p: p.message_index or 0)
            return pearls

        except Exception as e:
            print(f"[Librarian] Error getting thread {thread_id}: {e}")
            return []

    # =========================================================================
    # STATISTICS AND EXPORT
    # =========================================================================

    def get_stats(self) -> Dict[str, Any]:
        """Get vault statistics."""
        self._refresh_stats()

        deleted_count = len(self.get_deleted_pearl_ids())

        category_counts = {}
        for cat in MemoryCategory:
            memories = self.get_by_category(cat.value, limit=1000)
            if memories:
                category_counts[cat.value] = len(memories)

        importance_counts = {}
        for imp in ImportanceLevel:
            memories = self.get_by_importance(imp.value, limit=1000)
            if memories:
                importance_counts[imp.value] = len(memories)

        return {
            "model_id": self.model_id,
            "vault_path": str(self.vault_path),
            "pearl_count": self._pearl_count,
            "deleted_count": deleted_count,
            "active_count": self._pearl_count - deleted_count,
            "last_update": self._last_update,
            "by_category": category_counts,
            "by_importance": importance_counts,
            "core_pearls": len(self.get_core_pearls()),
            "vault_exists": self.vault_path.exists(),
            # Legacy compatibility
            "memory_count": self._pearl_count - deleted_count
        }

    def export(self) -> Dict[str, Any]:
        """Export all Pearls from the vault."""
        all_pearls = []
        deleted_ids = self.get_deleted_pearl_ids()

        for cat in MemoryCategory:
            try:
                find_result = self._mv.find(f"category:{cat.value}", k=10000, mode="lex")
                hits = _extract_hits_from_result(find_result, f"export.{cat.value}")
                for hit in hits:
                    hit_dict = _safe_parse_hit(hit, f"export.{cat.value}.hit")
                    label = hit_dict.get("label", "")
                    if "deletion_marker" in label:
                        continue
                    pearl = Pearl.from_memvid_hit(hit_dict, self.model_id)
                    pearl_dict = pearl.to_dict()
                    pearl_dict["is_deleted"] = pearl.id in deleted_ids
                    all_pearls.append(pearl_dict)
            except Exception:
                pass

        # Deduplicate
        seen_ids = set()
        unique_pearls = []
        for p in all_pearls:
            pid = p.get("pearl_id")
            if pid and pid not in seen_ids:
                seen_ids.add(pid)
                unique_pearls.append(p)

        unique_pearls.sort(key=lambda p: p.get("created_at", ""))

        return {
            "model_id": self.model_id,
            "exported_at": datetime.now().isoformat(),
            "vault_path": str(self.vault_path),
            "pearl_count": len(unique_pearls),
            "deleted_count": len(deleted_ids),
            "pearls": unique_pearls,
            "statistics": self.get_stats(),
            # Legacy compatibility
            "memories": [
                {
                    "memory_id": p["pearl_id"],
                    "content": p["full_content"],
                    "category": p["category"],
                    "importance": p["importance"],
                    "tags": p["tags"],
                    "created_at": p["created_at"]
                }
                for p in unique_pearls
                if not p.get("is_deleted")
            ]
        }

    # =========================================================================
    # CONTEXT FORMATTING (Legacy - prefer using Synthesizer)
    # =========================================================================

    def format_core_memories_for_prompt(self) -> str:
        """Format core memories for prompt (legacy)."""
        core = self.get_core_pearls()
        if not core:
            return ""

        parts = [
            "## Core Knowledge (Always Remember):\n"
            "These are fundamental things you know about this user:\n"
        ]

        for pearl in core:
            tag_str = ", ".join(pearl.tags[:3]) if pearl.tags else ""
            parts.append(f"* [{tag_str}] {pearl.full_content[:500]}...")

        return "\n".join(parts)

    def format_ai_self_for_prompt(self, include_history: bool = False) -> str:
        """Format AI self knowledge for prompt (legacy)."""
        memories = self.get_ai_self_memories()
        if not memories:
            return ""

        parts = [
            "## Your Inner Life & Perspective:\n"
        ]

        for mem in memories[:10]:
            parts.append(f"* {mem.content[:300]}...")

        return "\n".join(parts)

    def get_context_for_prompt(
        self,
        query: str,
        max_results: int = 5,
        include_core: bool = True,
        include_ai_self: bool = True,
        include_recent: int = 3,
        framing: str = "lived"
    ) -> str:
        """
        Get context for prompt injection (legacy method).

        NOTE: For the Librarian architecture, you should:
        1. Call get_raw_pearls_for_synthesis() to get Pearls
        2. Pass to Synthesizer to create detailed abstracts
        3. Inject the abstracts into the prompt

        This method provides backward compatibility but doesn't use
        the Synthesizer - it just truncates content.
        """
        context_parts = []

        if include_core:
            core_context = self.format_core_memories_for_prompt()
            if core_context:
                context_parts.append(core_context)
                context_parts.append("")

        if include_ai_self:
            ai_self_context = self.format_ai_self_for_prompt()
            if ai_self_context:
                context_parts.append(ai_self_context)
                context_parts.append("")

        if include_recent > 0:
            recent = self.get_recent(limit=include_recent)
            if recent:
                context_parts.append("**Recent conversations:**")
                for mem in recent:
                    context_parts.append(f"* {mem.content[:300]}...")
                context_parts.append("")

        if query.strip():
            results = self.search_pearls(query, limit=max_results)
            if results:
                context_parts.append(
                    "**Relevant past exchanges** (use Synthesizer for full context):\n"
                )
                for result in results:
                    context_parts.append(f"* {result.pearl.full_content[:400]}...")

        return "\n".join(context_parts)


# =============================================================================
# Vault Manager
# =============================================================================

class VaultManager:
    """Central manager for all model memory vaults."""

    def __init__(
        self,
        vaults_dir: Optional[Path] = None,
        embedding_model: Optional[str] = None
    ):
        if vaults_dir is None:
            from config import config
            vaults_dir = config.VAULTS_DIR
        self.vaults_dir = Path(vaults_dir)
        self.vaults_dir.mkdir(parents=True, exist_ok=True)
        self.embedding_model = embedding_model or DEFAULT_EMBEDDING_MODEL
        self._stores: Dict[str, MemvidStore] = {}

    def get_store(self, model_id: str) -> MemvidStore:
        """Get or create a vault for a specific model."""
        if model_id not in self._stores:
            self._stores[model_id] = MemvidStore(
                model_id,
                self.vaults_dir,
                embedding_model=self.embedding_model
            )
        return self._stores[model_id]

    def list_models(self) -> List[str]:
        """List all models with active vault connections."""
        return list(self._stores.keys())

    def get_all_vault_files(self) -> List[str]:
        """List all models that have vault files."""
        if not self.vaults_dir.exists():
            return []
        return [f.stem for f in self.vaults_dir.glob("*.mv2")]

    def get_all_stats(self) -> Dict[str, Any]:
        """Get statistics for all vaults."""
        all_stats = {
            "vaults_dir": str(self.vaults_dir),
            "active_models": self.list_models(),
            "all_vault_files": self.get_all_vault_files(),
            "models": {}
        }

        for model_id in self.get_all_vault_files():
            try:
                store = self.get_store(model_id)
                all_stats["models"][model_id] = store.get_stats()
            except Exception as e:
                all_stats["models"][model_id] = {"error": str(e)}

        return all_stats

    def export_all(self) -> Dict[str, Any]:
        """Export Pearls from all vaults."""
        exports = {
            "exported_at": datetime.now().isoformat(),
            "vaults_dir": str(self.vaults_dir),
            "models": {}
        }

        for model_id in self.get_all_vault_files():
            try:
                store = self.get_store(model_id)
                exports["models"][model_id] = store.export()
            except Exception as e:
                exports["models"][model_id] = {"error": str(e)}

        return exports

    def close_all(self):
        """Close all vault connections."""
        for store in self._stores.values():
            store.close()
        self._stores.clear()


# Global singleton
_vault_manager: Optional[VaultManager] = None


def get_vault_manager(vaults_dir: Optional[Path] = None) -> VaultManager:
    """Get or create the global vault manager."""
    global _vault_manager
    if _vault_manager is None:
        _vault_manager = VaultManager(vaults_dir)
    return _vault_manager


def get_store(model_id: str) -> MemvidStore:
    """Convenience function to get a model's vault store."""
    from config import config
    return get_vault_manager(config.VAULTS_DIR).get_store(model_id)
